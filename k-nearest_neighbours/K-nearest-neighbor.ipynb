{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beneficial-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementing kNN (k-Nearest Neighbors Algorithm) using only Python.\n",
    "dataset: https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival\n",
    "\n",
    "Dataset Description: The dataset contains cases from a study that was conducted\n",
    "                     between 1958 and 1970 at the University of Chicago's Billings\n",
    "                     Hospital on the survival of patients who had undergone surgery\n",
    "                     for breast cancer.\n",
    "\n",
    "Dataset Attributes Description: 1. Age of patient at time of operation (numerical)\n",
    "                                2. Patient's year of operation (year - 1900, numerical)\n",
    "                                3. Number of positive axillary nodes detected (numerical)\n",
    "                                4. Survival status (class attribute)\n",
    "                                     1 = the patient survived 5 years or longer\n",
    "                                     2 = the patient died within 5 year\n",
    "'''\n",
    "\n",
    "#sample list\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "junior-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data file\n",
    "with open('/Users/rohithebbar/Desktop/Machine_learning_projects/k-nearest_neighbour/data/haberman/haberman.data','r')as f:\n",
    "    for line in f.readlines():\n",
    "        attributes = line.replace('\\n', '').split(',')\n",
    "        # converting items from the list of attributes (string to integer)\n",
    "        samples.append([int(attribute) for attribute in attributes])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "diverse-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the data and returning the information\n",
    "def dataset_info(samples, verbose = True):\n",
    "    # displaying number of samples\n",
    "    if verbose:\n",
    "        print(f'Number of samples : {len(samples)}')\n",
    "    \n",
    "    # Initialising the counting variables for each label\n",
    "    label_1, label_2 = 0, 0\n",
    "    for sample in samples:\n",
    "        if sample[-1] == 1:\n",
    "            label_1 += 1\n",
    "        else:\n",
    "            label_2 += 1\n",
    "        \n",
    "    # Displaying number of samples  of each label\n",
    "    if verbose:\n",
    "        print(f'Number of samples of label_1 : {(label_1)}')\n",
    "   \n",
    "        print(f'Number of samples of label_2 : {(label_2)}')\n",
    "    # return a tuple with the number of samples and the number \n",
    "    # of samples of each label\n",
    "        \n",
    "    return len(samples), label_1, label_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "rocky-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples : 612\n",
      "Number of samples of label_1 : 450\n",
      "Number of samples of label_2 : 162\n"
     ]
    }
   ],
   "source": [
    "# unpacking return tuple of dataset_info function\n",
    "_ , label_1, label_2 = dataset_info(samples, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "removed-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of the dataset to include in the train split (60%)\n",
    "p = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "powered-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the test and training samples list\n",
    "train, test = [], []\n",
    "\n",
    "# Calculating the maximum amount of training samples per label\n",
    "max_label_1, max_label_2 = int(p * label_1), int(p * label_2)\n",
    "\n",
    "# Total amount of training samples\n",
    "total_of_train_samples = max_label_1 + max_label_2\n",
    "\n",
    "# Initializing labels counters\n",
    "count_label_1, count_label_2 = 0, 0\n",
    "\n",
    "for sample in samples:\n",
    "    # If the sum of the counters is less than the total amount of training samples\n",
    "    if (count_label_1 + count_label_2) < (total_of_train_samples):\n",
    "        # Adding sample to training set\n",
    "        train.append(sample)\n",
    "        if (sample[-1] == 1) and (count_label_1 < max_label_1):\n",
    "            count_label_1 += 1\n",
    "        else:\n",
    "            count_label_2 += 1\n",
    "    else:\n",
    "        # Adding sample to list of test set\n",
    "        test.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "better-brick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Train Samples\n",
      "Number of samples : 367\n",
      "Number of samples of label_1 : 277\n",
      "Number of samples of label_2 : 90\n",
      "----------------------------------\n",
      "Test Samples\n",
      "Number of samples : 245\n",
      "Number of samples of label_1 : 173\n",
      "Number of samples of label_2 : 72\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Displaying information about test and training samples\n",
    "print('----------------------------------')\n",
    "print('Train Samples')\n",
    "dataset_info(train)\n",
    "print('----------------------------------')\n",
    "print('Test Samples')\n",
    "dataset_info(test)\n",
    "print('----------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "funny-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance\n",
    "import math\n",
    "def euclidean_distance(v1, v2):\n",
    "    # Getting vector 1 size and initializing summing variable \n",
    "    length, summation  =  len(v1), 0\n",
    "    \n",
    "    # Adding the square of the difference of the values of the two vectors\n",
    "    for i in range(length - 1):\n",
    "        # Adding the square of the difference of the values of the two vectors\n",
    "        summation += math.pow(v1[i] - v2[i], 2)\n",
    "        \n",
    "        # Returning the square root of the sum\n",
    "    return math.sqrt(summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "severe-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing euclidian_distance function\n",
    "v1 = [1, 2, 3]\n",
    "v2 = [2, 1, 5]\n",
    "euclidean_distance(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "anticipated-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing KNN\n",
    "def KNN(train , new_sample, K):\n",
    "    # Initializing dict of distances and variable with size of training set\n",
    "    distances, train_length = {}, len(train)\n",
    "    # Calculating the Euclidean distance between the new\n",
    "    # sample and the values of the training sample\n",
    "    for i in range(train_length):\n",
    "        d = euclidean_distance(train[i], new_sample)\n",
    "        distances[i] = d\n",
    "        \n",
    "    # Selecting the K nearest neighbors\n",
    "    k_neigh = sorted(distances, key = distances.get)[:]\n",
    "    \n",
    "    # Initializing labels counters\n",
    "    label_1, label_2 = 0, 0\n",
    "    for index in k_neigh:\n",
    "        if train[index][-1] == 1:\n",
    "            label_1 += 1\n",
    "        else:\n",
    "            label_2 += 1\n",
    "    if label_1 > label_2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "explicit-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample \n",
      "[44, 64, 6, 2]\n",
      "Label: 2\n",
      "---------------------------\n",
      "kNN return \n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Testing kNN function\n",
    "print(\"New sample \\n{}\".format(test[12]))\n",
    "print(\"Label: %d\" %(test[12][3]))\n",
    "print('---------------------------')\n",
    "print(\"kNN return \")\n",
    "print('Label: {}'.format(KNN(train, test[12], K=7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "perceived-sheffield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 367\n",
      "Number of test samples: 245\n",
      "Total of hits: 173\n",
      "Number of hits (Percentage): 70.61%\n"
     ]
    }
   ],
   "source": [
    "# Testing KNN and displaying results\n",
    "# Initialising the hit counter\n",
    "hit_counter = 0\n",
    "\n",
    "# performing knn on all the test samples\n",
    "for sample in test:\n",
    "    label = KNN(train, sample, K = 7)\n",
    "    # Comparing method result with actual sample result\n",
    "    if sample[-1] == label:\n",
    "        hit_counter += 1\n",
    "print('Number of train samples: %d' % len(train))\n",
    "print('Number of test samples: %d' % len(test))\n",
    "print('Total of hits: %d' % hit_counter)\n",
    "print('Number of hits (Percentage): %.2f%%' % (100 * hit_counter / len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydlenv",
   "language": "python",
   "name": "mydlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
